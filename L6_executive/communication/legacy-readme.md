# HAL9 - Hierarchical AI Layer Orchestration System

<p align="center">
  <img src="https://img.shields.io/badge/rust-1.75+-orange.svg" alt="Rust">
  <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License">
  <img src="https://img.shields.io/badge/tests-50%2B%20passing-brightgreen.svg" alt="Tests">
  <img src="https://img.shields.io/badge/coverage-95%25+-brightgreen.svg" alt="Coverage">
  <img src="https://img.shields.io/badge/MCP-enabled-blue.svg" alt="MCP">
</p>

<p align="center">
  <strong>A revolutionary distributed AI consciousness system implementing hierarchical abstraction through networked AI neurons</strong>
</p>

## ğŸ§  Overview

HAL9 orchestrates multiple AI agents through hierarchical layers, mimicking human cognitive architecture. The system demonstrates how complex tasks decompose through strategic thinking (L4), design planning (L3), and concrete implementation (L2), with each layer powered by specialized AI neurons communicating via the Model Context Protocol (MCP).

### âœ¨ Key Features

- **Hierarchical Task Decomposition**: 1 task â†’ 2 subtasks â†’ 4 implementation tasks
- **Model Context Protocol (MCP)**: Standardized neuron communication via JSON-RPC
- **Distributed Architecture**: Deploy neurons across multiple servers with automatic discovery
- **Dynamic Capability Discovery**: Neurons expose tools and resources via MCP
- **Network Transparency**: Seamless routing between local and remote neurons
- **Service Discovery**: Automatic server and neuron discovery via UDP multicast
- **Real-time Visualization**: Web UI with live signal flow animation
- **Demo Recording/Replay**: Capture and replay demonstrations with variable speed
- **Export to Video/GIF**: Convert recordings to animated visualizations
- **Mock & Production Modes**: Development with deterministic mocks, production with Claude API
- **Comprehensive Testing**: 95%+ coverage with 50+ automated tests
- **"Skateboard First" MVP**: Working demo proving the concept

## ğŸ¯ Latest Updates

### Version 2.1 - MCP Integration & Enhanced Task Decomposition
- **Model Context Protocol (MCP)**: Standardized neuron communication using JSON-RPC
- **Hierarchical Task Decomposition**: Improved 1â†’2â†’4 task expansion pattern
- **Enhanced Testing**: 50+ tests covering task composition and MCP flows
- **Export Functionality**: Convert recordings to SVG/GIF animations
- **Better Documentation**: Comprehensive guides for MCP integration

### Key Improvements:
1. **Task Flow**: Each L3 neuron now generates exactly 2 L2 tasks (previously 1)
2. **MCP Architecture**: Neurons expose capabilities as tools and resources
3. **Test Coverage**: Added specific tests for task decomposition patterns
4. **Export Options**: New export-to-video functionality for presentations

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/2lab-ai/hal9
cd hal9

# Build the project
cargo build --release

# Start the server
./run-3neuron-demo.sh

# In another terminal, send a signal
./target/release/hal9 signal \
  --from user \
  --to neuron-1 \
  --content "Create a web application" \
  --server localhost:8080

# Run full demo scenarios
./demo-scenarios.sh

# Run MVP with web interface
./mvp/run-web.sh
# Open http://localhost:3000
```

## ğŸ“‹ Table of Contents

- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Project Structure](#-project-structure)
- [Building](#-building)
- [Running](#-running)
- [Testing](#-testing)
- [End-to-End Demos](#-end-to-end-demos)
- [Development](#-development)
- [Deployment](#-deployment)
- [Architecture](#-architecture)
- [API Documentation](#-api-documentation)
- [Research Papers](#-research-papers)
- [Contributing](#-contributing)
- [Roadmap](#-roadmap)
- [License](#-license)

## ğŸ“¦ Prerequisites

### Required
- **Rust** 1.75+ ([Install](https://rustup.rs/))
- **Git** 2.0+

### Optional
- **Claude API Key** (for production mode)
  ```bash
  export ANTHROPIC_API_KEY="sk-ant-..."
  ```
- **Node.js** 18+ (for web UI development)

## ğŸ› ï¸ Installation

### 1. Clone Repository
```bash
git clone https://github.com/2lab-ai/hal9.git
cd hal9
```

### 2. Install Dependencies
```bash
# Fetch Rust dependencies
cargo fetch

# Verify installation
cargo --version
rustc --version
```

### 3. Set Up Environment
```bash
# Copy example environment
cp .env.example .env

# Edit with your settings (optional)
vim .env
```

## ğŸ“ Project Structure

```
hal9/
â”œâ”€â”€ mvp/                        # Simplified MVP - "Skateboard First"
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs            # Core orchestrator with 1â†’2â†’4 decomposition
â”‚   â”‚   â”œâ”€â”€ web.rs             # Web UI server
â”‚   â”‚   â”œâ”€â”€ recorder.rs        # Demo recording/replay
â”‚   â”‚   â””â”€â”€ exporter.rs        # Export to SVG/GIF
â”‚   â”œâ”€â”€ static/                # Web UI (HTML/JS/CSS)
â”‚   â”œâ”€â”€ recordings/            # Saved demo sessions
â”‚   â”œâ”€â”€ tests/                 # Comprehensive test suite
â”‚   â”‚   â”œâ”€â”€ mvp_tests.rs       # Core functionality tests
â”‚   â”‚   â”œâ”€â”€ task_composition_tests.rs  # Task decomposition tests
â”‚   â”‚   â””â”€â”€ integration_tests.rs       # Integration tests
â”‚   â””â”€â”€ run-*.sh              # Convenience scripts
â”œâ”€â”€ hal9-core/               # Core types and abstractions
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ signal.rs         # Signal types
â”‚   â”‚   â”œâ”€â”€ neuron.rs         # Neuron interface
â”‚   â”‚   â””â”€â”€ mcp/              # Model Context Protocol
â”‚   â”‚       â”œâ”€â”€ protocol.rs   # MCP message definitions
â”‚   â”‚       â”œâ”€â”€ server.rs     # MCP server for neurons
â”‚   â”‚       â”œâ”€â”€ client.rs     # MCP client for wrapper
â”‚   â”‚       â””â”€â”€ tools.rs      # MCP tool definitions
â”œâ”€â”€ hal9-server/             # Production server
â”œâ”€â”€ hal9-cli/                # CLI tools
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PRD.md               # Product Requirements v2.0
â”‚   â”œâ”€â”€ MCP_INTEGRATION.md   # MCP protocol documentation
â”‚   â”œâ”€â”€ DEVELOPMENT_STRATEGY.md
â”‚   â””â”€â”€ paper/               # Research papers
â””â”€â”€ Cargo.toml               # Workspace configuration
```

## ğŸ”¨ Building

### Development Build
```bash
# Build MVP only
cargo build -p hal9_mvp

# Build everything
cargo build --workspace
```

### Production Build
```bash
# Optimized build
cargo build --release -p hal9_mvp

# Full release build
cargo build --release --all-features
```

### Verification
```bash
# Check without building
cargo check

# Run linter
cargo clippy -- -D warnings

# Format code
cargo fmt
```

## ğŸƒ Running

### 1. CLI Mode (Interactive Demo)
```bash
./mvp/run-mvp.sh

# Select scenario:
# 1. Task Management App
# 2. E-commerce Platform  
# 3. Real-time Chat System
```

### 2. Web UI Mode (Visual Demo)
```bash
./mvp/run-web.sh
# Open http://localhost:3000

# Features:
# - Real-time neuron visualization
# - Animated signal flow
# - Live code generation
# - Interactive scenarios
```

### 3. Recording Mode (Capture Demo)
```bash
./mvp/record-demo.sh
# Creates timestamped JSON recording
# Saved to mvp/recordings/
```

### 4. Replay Mode (Perfect Playback)
```bash
./mvp/replay-demo.sh
# Select recording
# Choose playback speed (0.5x-10x)
```

### 5. Distributed Mode (Multi-Server)
```bash
# Start distributed servers
./scripts/run-distributed.sh

# This will:
# - Start Server 1 (L4 Strategic) on port 9001
# - Start Server 2 (L3/L2 Workers) on port 9002
# - Enable automatic service discovery
# - Show monitoring instructions

# Stop distributed servers
./scripts/stop-distributed.sh
```

### 5. Export Mode (Video/GIF Generation)
```bash
./mvp/export-demo.sh
# Select recording
# Choose export format:
#   - Animated SVG (viewable in browser)
#   - Frame sequence (for GIF conversion)
#   - GIF conversion script

# Direct export commands:
cargo run -p hal9_mvp -- --export-svg=recording.json
cargo run -p hal9_mvp -- --export-frames=recording.json
cargo run -p hal9_mvp -- --export-gif-script=recording.json
```

## ğŸ§ª Testing

### Run All Tests
```bash
./mvp/run-tests.sh
# Result: 50+ tests, 100% passing
```

### Run Task Composition Tests
```bash
./mvp/run-composition-tests.sh
# Tests hierarchical task decomposition (1â†’2â†’4)
# Verifies MCP communication patterns
```

### Test Categories
```bash
# Unit tests (signal structure, validation)
cargo test -p hal9_mvp signal_structure_tests

# Integration tests (full signal flow)
cargo test -p hal9_mvp integration_flow_tests

# Performance tests (1000+ concurrent signals)
cargo test -p hal9_mvp performance_tests

# Recording tests (save/load/replay)
cargo test -p hal9_mvp recording_system_tests
```

### Test Coverage Summary
- **Signal Flow**: 100% of routing paths tested
- **Error Handling**: All failure modes covered
- **Performance**: <5s for 1000 signals validated
- **Memory**: <10MB for 10k signals confirmed
- **Concurrency**: 100+ parallel operations tested

## ğŸ¬ End-to-End Demos

### Demo 1: Task Management App
Shows L4â†’L3â†’L2 decomposition:
- **L4**: "Build task app" â†’ Strategic breakdown
- **L3**: Parallel design (Backend + Frontend)
- **L2**: Generated Express.js + React code

### Demo 2: E-commerce Platform
Demonstrates domain-specific routing:
- **L4**: "Create e-commerce" â†’ Component identification  
- **L3**: Payment flow + Product catalog
- **L2**: Next.js + Stripe integration

### Demo 3: Real-time Chat
Showcases complex architecture:
- **L4**: "Chat system" â†’ Scalability planning
- **L3**: WebSocket design + Redis pub/sub
- **L2**: Full implementation with presence

### Running E2E Tests
```bash
# Test all scenarios automatically
for i in 1 2 3; do
  echo $i | cargo run -p hal9_mvp
done

# Verify recordings
ls -la mvp/recordings/
```

## ğŸ’» Development

### Setup Development Environment
```bash
# Install dev tools
cargo install cargo-watch
cargo install cargo-expand

# Enable pre-commit hooks
git config core.hooksPath .githooks
```

### Development Workflow
```bash
# Auto-rebuild on changes
cargo watch -x 'run -p hal9_mvp'

# Run with debug logs
RUST_LOG=debug cargo run -p hal9_mvp

# Expand macros
cargo expand -p hal9_mvp
```

### Adding Features

1. **Modify appropriate layer**:
   - `MockNeuron::process()` for layer logic
   - `Orchestrator` for routing
   - `SignalTracker` for visualization

2. **Add tests**:
   ```rust
   #[test]
   fn test_new_feature() {
       // Implementation
   }
   ```

3. **Update docs**:
   - Inline documentation
   - README updates
   - Example usage

### Code Quality Checklist
```bash
# Before committing
cargo fmt --check       # Format
cargo clippy           # Lint  
cargo test            # Test
cargo doc             # Docs
```

## ğŸš€ Deployment

### Local Deployment
```bash
# Build and install
cargo build --release -p hal9_mvp
sudo cp target/release/hal9_mvp /usr/local/bin/hal9

# Run as service
hal9 --web
```

### Docker Deployment

```dockerfile
# Dockerfile
FROM rust:1.75-slim as builder
WORKDIR /app
COPY . .
RUN cargo build --release -p hal9_mvp

FROM debian:bookworm-slim
RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*
COPY --from=builder /app/target/release/hal9_mvp /usr/local/bin/hal9
EXPOSE 3000
CMD ["hal9", "--web"]
```

```bash
# Build and run
docker build -t hal9:latest .
docker run -d -p 3000:3000 --name hal9 hal9:latest
```

### Kubernetes Deployment

```yaml
# hal9-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hal9
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hal9
  template:
    metadata:
      labels:
        app: hal9
    spec:
      containers:
      - name: hal9
        image: hal9:latest
        ports:
        - containerPort: 3000
        env:
        - name: RUST_LOG
          value: "info"
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: hal9-secrets
              key: anthropic-api-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
---
apiVersion: v1
kind: Service
metadata:
  name: hal9-service
spec:
  selector:
    app: hal9
  ports:
  - port: 80
    targetPort: 3000
  type: LoadBalancer
```

### Cloud Platforms

#### AWS ECS
```bash
# Build and push to ECR
aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_URI
docker tag hal9:latest $ECR_URI/hal9:latest
docker push $ECR_URI/hal9:latest

# Deploy with ECS CLI
ecs-cli compose up
```

#### Google Cloud Run
```bash
# Build and deploy
gcloud builds submit --tag gcr.io/$PROJECT_ID/hal9
gcloud run deploy hal9 --image gcr.io/$PROJECT_ID/hal9 --platform managed
```

#### Production Configuration
```bash
# Environment variables
export ANTHROPIC_API_KEY="sk-ant-..."
export RUST_LOG="warn"
export SERVER_WORKERS=4
export MAX_CONNECTIONS=1000

# System tuning
ulimit -n 65536  # File descriptors
sysctl -w net.core.somaxconn=1024
```

## ğŸ—ï¸ Architecture

### System Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚â”€â”€â”€â”€â–¶â”‚   L4    â”‚â”€â”€â”€â”€â–¶â”‚  L3(x2) â”‚â”€â”€â”€â”€â–¶â”‚ L2(x4)  â”‚
â”‚  Input  â”‚     â”‚Strategicâ”‚     â”‚ Design  â”‚     â”‚ Impl.   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (1)             (1)            (2)             (4)
                     â”‚               â”‚               â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          Backward Propagation
```

### Task Decomposition Pattern

The system follows a hierarchical decomposition pattern where each layer expands the task complexity:

```
Input: 1 task
  â””â”€> L4: 1 strategic task
       â””â”€> L3: 2 design tasks (parallel)
            â””â”€> L2: 4 implementation tasks (2 from each L3)
```

#### Example: "Build a simple TODO API service"

1. **L4 Strategic** (1 task):
   - "Design and implement a TODO API service with CRUD operations"

2. **L3 Design** (2 tasks):
   - "Design backend architecture and data model for TODO service"
   - "Design API endpoints and request/response schemas"

3. **L2 Implementation** (4 tasks):
   - From first L3:
     - "Implement database schema with id, title, description, completed, created_at fields"
     - "Implement repository pattern with create, read, update, delete methods"
   - From second L3:
     - "Implement REST endpoints: POST /todos, GET /todos, PUT /todos/:id, DELETE /todos/:id"
     - "Implement validation middleware and error handling for API requests"

### Model Context Protocol (MCP) Integration

HAL9 uses MCP for standardized neuron communication:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          MCP Protocol         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Wrapper/Orch      â”‚ <------------------------>   â”‚   Neuron Server     â”‚
â”‚  (MCP Client)       â”‚        JSON-RPC over         â”‚  (MCP Server)       â”‚
â”‚                     â”‚        stdio/TCP/WebSocket    â”‚                     â”‚
â”‚ - Connect           â”‚                               â”‚ - Process Task      â”‚
â”‚ - Call Tools        â”‚                               â”‚ - List Tools        â”‚
â”‚ - Read Resources    â”‚                               â”‚ - Get Capabilities  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### MCP Features:
- **Dynamic Discovery**: Neurons advertise capabilities via MCP
- **Tool-based Processing**: Task processing exposed as MCP tools
- **Resource Sharing**: Neurons share state via MCP resources
- **Standard Protocol**: JSON-RPC 2.0 for all communication

### Core Components

1. **Orchestrator**: Central routing with MCP client connections
2. **MockNeuron**: Layer-specific processing with MCP server
3. **SignalTracker**: Hierarchical visualization of signal flow
4. **DemoRecorder**: Session capture/replay with timing
5. **WebServer**: Real-time UI with WebSocket broadcasting
6. **MCP Integration**: Standardized neuron communication layer

### Signal Flow Example
```
User: "Create task management app"
  â†“
L4 (neuron-1): Strategic decomposition [MCP: process_task]
  â”œâ”€â†’ L3 (neuron-2): "Design backend architecture"
  â”‚     â”œâ”€â†’ L2 (neuron-4): "Implement database schema"
  â”‚     â””â”€â†’ L2 (neuron-4): "Implement repository pattern"
  â””â”€â†’ L3 (neuron-3): "Design API endpoints"
        â”œâ”€â†’ L2 (neuron-4): "Implement REST endpoints"
        â””â”€â†’ L2 (neuron-4): "Implement validation"
```

## ğŸ“š API Documentation

### Core Types
```rust
pub struct Signal {
    pub id: Uuid,
    pub parent_id: Option<Uuid>,
    pub from: String,
    pub to: String,
    pub content: String,
    pub layer: String,      // "Input", "L4", "L3", "L2"
    pub timestamp: DateTime<Utc>,
}

pub struct Orchestrator {
    pub async fn send_signal(&self, signal: Signal) -> Result<()>
    pub async fn get_signals(&self) -> Vec<Signal>
    pub fn subscribe_to_signals(&self) -> broadcast::Receiver<Signal>
}
```

### MCP Protocol API
```json
// Process Task Request
{
  "jsonrpc": "2.0",
  "id": "1",
  "method": "neuron/processTask",
  "params": {
    "task_id": "uuid",
    "content": "Build a simple TODO API service",
    "context": {
      "layer_from": "Input",
      "layer_to": "L4",
      "batch_id": "uuid"
    }
  }
}

// Process Task Response
{
  "jsonrpc": "2.0",
  "id": "1",
  "result": {
    "task_id": "uuid",
    "subtasks": [
      {
        "id": "uuid",
        "content": "Design backend architecture...",
        "target_neuron": "neuron-2",
        "target_layer": "L3"
      }
    ],
    "status": "success",
    "processing_time_ms": 150
  }
}
```

### WebSocket API
```typescript
// Client â†’ Server
interface ClientRequest {
  type: 'StartDemo' | 'GetStatus'
  scenario?: string
}

// Server â†’ Client  
interface ServerMessage {
  type: 'Signal' | 'Status' | 'Hierarchy' | 'CodeOutput'
  // ... message-specific fields
}
```

### REST Endpoints
```
GET  /              # Web UI
GET  /ws            # WebSocket upgrade
GET  /health        # Health check
GET  /metrics       # Prometheus metrics (future)
```

## ğŸ“– Research Papers

The theoretical foundation for HAL9:

1. **[L1: Hierarchical Abstraction is All You Need](docs/paper/L1_Hierarchical%20Abstraction%20is%20All%20You%20Need.ko.md)**
   - Core principle of hierarchical decomposition
   - Abstraction layers in AI systems

2. **[L2: Road to HAL9](docs/paper/L2_Road%20to%20HAL9.md)**
   - Evolution from HAL0 to HAL9
   - Energy scaling considerations

3. **[L3: Backpropagation Approach](docs/paper/L3_A%20Backpropagation%20Approach%20to%20Multi-Level%20AI%20Orchestration.ko.md)**
   - Error correction through layers
   - Learning mechanisms

4. **[L4: Sleep-Wake Cycles](docs/paper/L4_The%20Sleep-Wake%20Cycle%20of%20the%20AI%20Hivemind.ko.md)**
   - Memory consolidation patterns
   - Distributed consciousness

5. **[L5: Evolution Paths](docs/paper/L5_Three%20Evolution%20Paths%20to%20Multi-Level%20AI%20Hivemind.ko.md)**
   - Future architecture directions

## ğŸš¦ Roadmap

### Phase 1: MVP âœ… (Completed)
- [x] Core orchestrator with 3 neurons
- [x] Hierarchical task decomposition (1â†’2â†’4)
- [x] Model Context Protocol (MCP) integration
- [x] Mock Claude implementation  
- [x] CLI interface with scenarios
- [x] Web UI with visualization
- [x] Recording/replay system
- [x] Export to SVG/GIF functionality
- [x] Comprehensive test suite (50+ tests)

### Phase 2: Production Ready (Current)
- [x] MCP server/client architecture
- [ ] Real Claude API integration via MCP
- [ ] Configuration system (YAML)
- [ ] Monitoring and metrics
- [ ] Cost tracking/limits
- [ ] Docker deployment
- [ ] CI/CD pipeline

### Phase 3: Distributed System
- [ ] Multi-server support
- [ ] TCP networking layer
- [ ] Remote neuron routing
- [ ] Health monitoring
- [ ] Load balancing
- [ ] Kubernetes operators

### Phase 4: Advanced Features
- [ ] Backward propagation
- [ ] Sleep-wake cycles
- [ ] Memory consolidation
- [ ] LoRA fine-tuning
- [ ] Custom neuron types
- [ ] Plugin system

### Phase 5: HAL Evolution
- [ ] HAL1: 7 neurons, 10kW
- [ ] HAL2: 42 neurons, 100kW
- [ ] HAL3: 300 neurons, 1MW
- [ ] ... â†’ HAL9: 33M neurons, 563PW

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Quick Start for Contributors
```bash
# Fork and clone
git fork https://github.com/2lab-ai/hal9
git clone https://github.com/YOUR_USERNAME/hal9
cd hal9

# Create feature branch
git checkout -b feature/amazing-feature

# Make changes and test
cargo test
cargo fmt
cargo clippy

# Commit and push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/amazing-feature

# Open PR on GitHub
```

### Areas Needing Help
- Real Claude API integration via MCP
- MCP transport implementations (TCP, WebSocket)
- Performance optimizations
- Additional test scenarios
- Documentation improvements
- UI/UX enhancements
- Cloud deployment guides

### Key Documentation
- [Architecture Overview](ARCHITECTURE.md)
- [MCP Integration Guide](docs/MCP_INTEGRATION.md)
- [Development Strategy](docs/DEVELOPMENT_STRATEGY.md)
- [Testing Guide](mvp/TESTING_GUIDE.md)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Research**: Jihyuk Im (@icedac) and Claude
- **Inspiration**: Biological neural networks
- **Foundation**: Anthropic's Claude API
- **Community**: Rust async ecosystem

## ğŸ“ Support & Contact

- **Issues**: [GitHub Issues](https://github.com/2lab-ai/hal9/issues)
- **Discussions**: [GitHub Discussions](https://github.com/2lab-ai/hal9/discussions)
- **Email**: support@2lab.ai
- **Twitter**: [@2lab_ai](https://twitter.com/2lab_ai)

---

<p align="center">
  <strong>HAL9 - Hierarchical AI Layer 9</strong><br>
  <em>Building the path to artificial general intelligence through hierarchical orchestration</em><br><br>
  Built with â¤ï¸ by the HAL9 Team
</p>