# Distributed 2HAL9 Configuration - Server 2
# This server hosts L3 and L2 neurons

server_id: "hal9-server-2"

# Server 2 hosts the L3 and L2 layers
neurons:
  # L3 Architecture neurons
  - id: "architect-1"
    layer: "L3"
    claude_command: "claude"
    forward_connections: 
      - "impl-backend"
      - "impl-frontend"
    backward_connections: 
      - "strategic-main"  # Remote neuron on server 1
    settings:
      model: "claude-3-sonnet-20240229"
      temperature: 0.5
      
  - id: "architect-2"
    layer: "L3"
    claude_command: "claude"
    forward_connections:
      - "impl-data"
      - "impl-infra"
    backward_connections:
      - "strategic-main"  # Remote neuron on server 1
    settings:
      model: "claude-3-sonnet-20240229"
      temperature: 0.5
  
  # L2 Implementation neurons
  - id: "impl-backend"
    layer: "L2"
    claude_command: "claude"
    forward_connections: []
    backward_connections: ["architect-1"]
    settings:
      model: "claude-3-haiku-20240307"
      temperature: 0.3
      
  - id: "impl-frontend"
    layer: "L2"
    claude_command: "claude"
    forward_connections: []
    backward_connections: ["architect-1"]
    settings:
      model: "claude-3-haiku-20240307"
      temperature: 0.3
      
  - id: "impl-data"
    layer: "L2"
    claude_command: "claude"
    forward_connections: []
    backward_connections: ["architect-2"]
    settings:
      model: "claude-3-haiku-20240307"
      temperature: 0.3
      
  - id: "impl-infra"
    layer: "L2"
    claude_command: "claude"
    forward_connections: []
    backward_connections: ["architect-2"]
    settings:
      model: "claude-3-haiku-20240307"
      temperature: 0.3

# Network configuration
network:
  enabled: true
  bind_address: "0.0.0.0:9002"
  discovery_enabled: true
  discovery_address: "239.255.42.99:8888"
  discovery_group: "production"
  max_connections: 100
  tls_enabled: false

# Claude configuration
claude:
  mode: "api"
  model: "claude-3-sonnet-20240229"
  temperature: 0.5
  max_tokens: 3000
  rate_limit: 60
  fallback_to_mock: true
  cost_controls:
    max_cost_per_hour: 10.0
    max_cost_per_day: 100.0
    max_tokens_per_request: 3000
    alert_threshold: 0.8
  
  # Mock responses for testing/fallback
  mock_responses:
    L3:
      - trigger: "default"
        response: |
          FORWARD_TO: impl-backend, impl-frontend
          CONTENT: Designing system components:
          - Backend API service
          - Frontend web interface
        delay_ms: 100
    L2:
      - trigger: "default"
        response: |
          RESULT: Implementation complete
          ```python
          # Generated implementation
          def process_request():
              return "Distributed processing complete"
          ```
        delay_ms: 50

# Monitoring
monitoring:
  enabled: true
  metrics_interval: 30
  log_level: "info"